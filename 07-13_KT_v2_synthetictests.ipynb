{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import astropy.units as u  \n",
    "import astropy.constants as c\n",
    "from astropy.coordinates import SkyCoord, Galactic, CartesianRepresentation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, join\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "bayestar_path = '/uufs/astro.utah.edu/common/home/u1371365/dustmaps_data/bayestar/bayestar2019.h5'\n",
    "from dustmaps.bayestar import BayestarQuery\n",
    "\n",
    "### NEW 03-20: implement the 10pc resolution Vergely map into dustmaps ###\n",
    "from dustmaps.vergely2022 import Vergely2022Query\n",
    "\n",
    "import h5py\n",
    "from dustapprox.models import PrecomputedModel\n",
    "\n",
    "import emcee\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_meta = Table(fits.open('../Data/230420_CAResiduals/CA_meta.fits')[1].data)\n",
    "CAresdir = '../Data/230420_CAResiduals/'\n",
    "starhorsepath = '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'\n",
    "starhorse = Table.read(starhorsepath, hdu = 1)\n",
    "starhorse = starhorse['APOGEE_ID', 'dist16', 'dist50', 'dist84', 'AV16', 'AV50', 'AV84']\n",
    "\n",
    "CA_meta = join(CA_meta, starhorse, keys = 'APOGEE_ID', join_type = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dustmap coordinates\n",
    "distance = np.linspace(0, 1000, 200)\n",
    "\n",
    "\n",
    "l0, b0 = (163., -8.0)\n",
    "l_ = np.linspace(l0 - 9., l0 + 9., 200)\n",
    "b_ = np.linspace(b0 - 9., b0 + 9., 200)\n",
    "l, b, d = np.meshgrid(l_, b_, distance)\n",
    "print(l.shape)\n",
    "\n",
    "coords = SkyCoord(l*u.deg, b*u.deg,\n",
    "                  distance=distance*u.pc, frame='galactic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Vergely+ (2022) dustmap for same points as Bayestar, now that it's in dustmaps\n",
    "A0Coeff = 1.052180128669157 # from 02-03dustmap_explore.ipynb, calculated via dustapprox\n",
    "\n",
    "vergelyquery = Vergely2022Query(map_fname = \n",
    "                                '/uufs/astro.utah.edu/common/home/u1371365/dustmaps_data/vergely2022/vergely22_extinction_density_resol_010pc.h5')\n",
    "vergely = vergelyquery(coords) * A0Coeff\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.imshow(np.sum(vergely * 5, axis = 2), origin = 'lower', cmap = 'binary', extent = (l0-9, l0+9, b0-9, b0+9))\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "ax.scatter(CA_meta['GLON'], CA_meta['GLAT'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda0 = 15272.42 \n",
    "sigma0 = 1.15\n",
    "\n",
    "def get_wavs(hdulist = None, rv = 0):\n",
    "    if hdulist is None:\n",
    "        CRVAL1 = 4.179\n",
    "        CDELT1 = 6e-06\n",
    "        LEN = 8575\n",
    "    else:\n",
    "        header = hdulist[1].header\n",
    "        CRVAL1 = header['CRVAL1']\n",
    "        CDELT1 = header['CDELT1']\n",
    "        LEN = header['NAXIS1']\n",
    "        \n",
    "    wavs = np.power(10, CRVAL1 + CDELT1 * np.arange(LEN))\n",
    "    wavs = wavs * (1 + rv / 3e5) # allows for shifting to observed frame from rest frame\n",
    "    return wavs\n",
    "\n",
    "wavs = get_wavs()\n",
    "window = (wavs > lambda0 -10) & (wavs < lambda0 + 10)\n",
    "window_inds = np.where(window)[0]\n",
    "wavs_window = wavs[window]\n",
    "window_mask = (wavs_window < lambda0) - 5 | (wavs_window > lambda0 + 5)\n",
    "\n",
    "def dopplershift(v, lambda0 = lambda0):\n",
    "     return (lambda0 * u.Angstrom * (c.c + v * u.km / u.s) / c.c).to(u.Angstrom).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ca_res(fname):\n",
    "    return str(CAresdir + str(fname))\n",
    "\n",
    "def select_stars(tab, l0, b0, radius = 1):\n",
    "    cond = np.sqrt((tab['GLON'] - l0)**2 + (tab['GLAT'] - b0)**2) < radius\n",
    "    return np.where(cond)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loff = 1\n",
    "boff = 1\n",
    "l_cen, b_cen, = (163 + loff , -8.4 + boff)\n",
    "s= select_stars(CA_meta, l_cen, b_cen, radius = .25)\n",
    "s1 = select_stars(CA_meta, l_cen +1 , b_cen +1 , radius = .23)\n",
    "s2 = select_stars(CA_meta, l_cen -1 , b_cen -1 , radius = .23)\n",
    "s3 = select_stars(CA_meta, l_cen - 2, b_cen - 2, radius = 0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(ll, bb):\n",
    "    l_sel = l_\n",
    "    b_sel = b_\n",
    "\n",
    "    return np.argmin(np.abs(l_sel - ll)), np.argmin(np.abs(b_sel - bb))\n",
    "\n",
    "def find_nearest_dist(d):\n",
    "    return np.argmin(np.abs(distance[:, np.newaxis] - d), axis = 0)\n",
    "\n",
    "\n",
    "def dAV_dd(l0, b0, bin_edges):\n",
    "    l_ind, b_ind = find_nearest(l0, b0)\n",
    "    sightline = np.copy(vergely[b_ind, l_ind, :]) #needs to be b then l then :\n",
    "\n",
    "    d_min, d_max = bin_edges\n",
    "\n",
    "    extinction = sightline[(distance > d_min) & (distance < d_max)]\n",
    "    return np.sum(extinction )\n",
    "\n",
    "def dAV_dd_star(l0, b0, bin_edges, distances):\n",
    "    l_ind, b_ind = find_nearest(l0, b0)\n",
    "    d_min, d_max = bin_edges\n",
    "    sightline = np.copy(vergely[b_ind, l_ind, :])\n",
    "    sightline[(distance < d_min) | (distance > d_max)] = 0\n",
    "    sightline_av = (np.cumsum(sightline)) \n",
    "    d_ind = find_nearest_dist(distances)\n",
    "\n",
    "    return np.nanmedian(sightline_av[d_ind])\n",
    "\n",
    "def Differential_Amplitude(dAv_dd, dd):\n",
    "     return  0.024 * dAv_dd * dd  # 1/(np.sqrt(2 * np.pi) * sigma0) * 102e-3 * dAv_dd * dd\n",
    "\n",
    "def dAV_dd_array(l, b, bins, star_dist, dmap_dist = distance):\n",
    "    l_ind, b_ind = find_nearest(l, b)\n",
    "    verg_sightline = np.copy(vergely[b_ind, l_ind, :]) \n",
    "    dAVdd = np.zeros(len(bins)-1)\n",
    "    dAVdd_all = np.zeros(len(bins)-1)\n",
    "    for i in range(len(dAVdd)):\n",
    "        bin_min, bin_max = bins[i], bins[i+1]\n",
    "        if bin_min < star_dist:\n",
    "            dist_max = bin_max\n",
    "            if bin_max >= star_dist:\n",
    "                dist_max = star_dist\n",
    "        else:\n",
    "            dist_max = -np.inf\n",
    "\n",
    "            \n",
    "        dAVdd[i] = np.sum(verg_sightline[(dmap_dist > bin_min) & (dmap_dist <= dist_max)])\n",
    "        dAVdd_all[i] = np.sum(verg_sightline[(dmap_dist > bin_min) & (dmap_dist <= bin_max)])\n",
    "\n",
    "    return dAVdd, dAVdd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sightline:\n",
    "    ### Container object for stars, sightline dAV_dd, velocity, and spaxel assignment.\n",
    "    def __init__(self, stars, bins = None, **kwargs):\n",
    "        self.stars = stars\n",
    "        dist = self.stars['DIST']\n",
    "\n",
    "        if bins is not None:\n",
    "            h = np.histogram(dist, bins)[0]\n",
    "            self.bins = np.insert(bins[1:][h != 0], 0, bins[0])\n",
    "            self.bin_inds = np.digitize(dist, bins)\n",
    "        else:\n",
    "            self.make_bins()\n",
    "            self.bin_inds = np.digitize(dist, self.bins)  \n",
    "        self.rvelo = np.zeros(len(self.bins) - 1)\n",
    "        self.get_DIBs()\n",
    "        self.init_signals = self.model_signals(self.rvelo, self.dAVdd)\n",
    "        \n",
    "    def make_bins(self, binsep = 10, dmin = 0):\n",
    "        ### Assigns stars to distance bins if bins are not already supplied.\n",
    "        dist = self.stars['DIST']\n",
    "        bins = np.sort(np.insert(np.delete(dist, np.where(dist <= dmin)[0]), 0, dmin))\n",
    "\n",
    "        i = 0\n",
    "        while i >= 0:\n",
    "            next_bin = np.min(bins[bins > bins[i]])\n",
    "            bins[i+1] = np.max([next_bin, bins[i] + binsep]) + 0.01\n",
    "            if bins[i+1] >= np.max(dist):\n",
    "                bins = bins[:i+2]\n",
    "                i = -np.inf\n",
    "            i = i+1\n",
    "        \n",
    "        self.bins = bins\n",
    "            \n",
    "    def get_DIBs(self):\n",
    "        signals = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        signal_errs = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        dAVdd = np.zeros((len(self.stars), len(self.bins)-1))\n",
    "        dAVdd_all = np.zeros((len(self.stars), len(self.bins)-1))\n",
    "\n",
    "        # dAVdd = np.zeros(len(self.bins))\n",
    "\n",
    "        for i in range(len(self.stars)):\n",
    "            star = self.stars[i]\n",
    "            res_hdul = fits.open(get_ca_res(star['FILE']))\n",
    "            signals[i, :] = res_hdul[1].data[window]\n",
    "            signal_errs[i, :] = res_hdul[2].data[window]\n",
    "            l, b = star['GLON'], star['GLAT']\n",
    "            dAVdd[i], dAVdd_all[i] = dAV_dd_array(l, b, self.bins, star['DIST'])\n",
    "        self.signals = signals\n",
    "        self.signal_errs = signal_errs\n",
    "        self.dAVdd = dAVdd\n",
    "        self.voxel_dAVdd = np.nanmedian(dAVdd_all, axis = 0)\n",
    "        self.voxel_dAVdd_std = np.nanstd(dAVdd_all, axis = 0, ddof = 1)\n",
    "        print(self.voxel_dAVdd.shape)\n",
    "        # self.dAVdd = dAV_dd_array(np.median(self.stars['GLON']), np.median(self.stars['GLAT']), \n",
    "        #                           self.bins, np.max(self.bins))\n",
    "\n",
    "    def model_signals(self, rvelo, dAVdd = None):\n",
    "        if dAVdd is None:\n",
    "            dAVdd = self.dAVdd\n",
    "        # print('dAVdd shape: ', dAVdd.shape)\n",
    "        signals = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        peak_wavelength = dopplershift(rvelo)\n",
    "        wavs_grid = np.tile(wavs_window, (len(self.bins) - 1, 1))\n",
    "        voxel_DIB_unscaled = np.exp(-(wavs_grid - peak_wavelength[:, np.newaxis])**2 / (2 * sigma0**2))\n",
    "        amp = Differential_Amplitude(dAVdd, self.bins[1:]-self.bins[:-1])\n",
    "\n",
    "        # def single_signal(bin_index, amp = amp):\n",
    "        #     amp[bin_index+1:] = 0\n",
    "        #     voxel_DIB_scaled = voxel_DIB_unscaled *  amp[:, np.newaxis] \n",
    "        #     summed_DIB = np.sum(voxel_DIB_scaled, axis = 0)\n",
    "        #     continuum = lambda x, m, b : m * (x - lambda0) + b\n",
    "        #     cont = continuum(wavs_window, m, b)\n",
    "\n",
    "        #     return summed_DIB  + cont \n",
    "        def single_signal(amp, bindex):\n",
    "            amp[bindex+1:] = 0\n",
    "            voxel_DIB_scaled = -voxel_DIB_unscaled *  amp[:, np.newaxis] \n",
    "            summed_DIB = np.sum(voxel_DIB_scaled, axis = 0)\n",
    "            # continuum = lambda x, m, b : m * (x - lambda0) + b\n",
    "            # cont = continuum(wavs_window, 0, b)\n",
    "\n",
    "            return summed_DIB  + 1 \n",
    "\n",
    "        for i in range(len(self.stars)):\n",
    "            star = self.stars[i]\n",
    "            dAVdd_star = dAVdd[i, :]\n",
    "            # amp = Differential_Amplitude(dAVdd_star, self.bins[1:]-self.bins[:-1])\n",
    "            amp = Differential_Amplitude(dAVdd_star, 5)\n",
    "\n",
    "            bin_index = self.bin_inds[i]\n",
    "            # signals[i, :] = single_signal(bin_index)\n",
    "            signals[i, :] = single_signal(amp, bin_index)\n",
    "        return signals\n",
    "            \n",
    "    ### + A vector of dAV_dd prior (e.g. sigma) with sigma_dAV_dd(d > d_star) = 0 \n",
    "\n",
    "\n",
    "    ### + A vector of velocities per distance bin\n",
    "\n",
    "    ### Consider Gaussian fitting each feature first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sightline(CA_meta[s])\n",
    "a1 = sightline(CA_meta[s1])\n",
    "a2 = sightline(CA_meta[s2])\n",
    "a3 = sightline(CA_meta[s3])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 4))\n",
    "ax = axs[0]\n",
    "\n",
    "for i in range(len(a.bins)-1): \n",
    "    ax.hlines(a.dAVdd[:, i], a.bins[i], a.bins[i+1])\n",
    "    ax.hlines(a.voxel_dAVdd[i], a.bins[i], a.bins[i+1], color = 'r')\n",
    "\n",
    "ax.plot([a.bins, a.bins], [np.zeros(len(a.bins)), np.ones(len(a.bins))], c='k', linestyle = 'dashed', linewidth = 0.5)\n",
    "ax.scatter(CA_meta[s][\"DIST\"], np.ones(len(CA_meta[s])) * 0.5)\n",
    "ax.set_xlabel('Distance (pc)')\n",
    "ax.set_yticklabels('')\n",
    "ax.set_xlim(290, 610)\n",
    "# axs[0].plot(a.bins[1:], a.dAVdd.T)\n",
    "\n",
    "\n",
    "\n",
    "axs[1].hist(a.stars['DIST'], a.bins, histtype = 'step')\n",
    "ymin, ymax = axs[1].get_ylim()\n",
    "axs[1].set_ylim(ymin, ymax)\n",
    "axs[1].plot([a.bins, a.bins], [np.zeros(len(a.bins)), ymax * np.ones(len(a.bins))], c='k', linestyle = 'dashed', linewidth = 0.5)\n",
    "axs[1].set_xlabel('Distance (pc)')\n",
    "fig.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_signals(self, rvelo, dAVdd = None):\n",
    "signals = np.zeros(a.signals.shape)\n",
    "signal_errs = np.zeros(a.signals.shape)\n",
    "def loglikely_2(v, av, sl = a, **kwargs):\n",
    "\n",
    "    # v = p[:int(len(p)/2)]\n",
    "    # av = p[int(len(p)/2):]\n",
    "    # av = np.tile(av, len(sl.stars)).reshape(len(sl.stars), -1)\n",
    "\n",
    "    signal = sl.signals\n",
    "    sigma = sl.signal_errs\n",
    "\n",
    "    # print('loglikely av shape' ,av.shape)\n",
    "    val = - 0.5 * np.nansum((signal - sl.model_signals(v, dAVdd = av))**2 / (sigma**2))\n",
    "    if np.isnan(val):\n",
    "        # print('fail loglikely')\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return val\n",
    "    # return - 0.5 * np.sum((signal - sl.model_signals(v, dAVdd = av))**2 / (sigma**2)) \n",
    "\n",
    "def logprior_v(v, v_max = 5, prior_mult = 1, **kwargs):\n",
    "    if (np.any(np.abs(v) > prior_mult * v_max)):\n",
    "        # print('logprior v -inf')\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def logprior_davdd(av, AV_base = 5, AV_max = 10):   \n",
    "    if (np.any(np.abs(av - AV_base) > AV_max)):\n",
    "        # print('av -inf')\n",
    "        return -np.inf\n",
    "    if ((np.any(av < 0))):\n",
    "        # print('logprior av -inf')\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def logprior_davdd_reg(av,sl, mask = None, **kwargs):\n",
    "    av = np.tile(av, len(sl.stars)).reshape(len(sl.stars), -1) # FOR NOW \n",
    "\n",
    "    mask = av == 0.0\n",
    "    av[mask] = np.nan\n",
    "\n",
    "    # avmed = np.nanmedian(av, axis = 0)\n",
    "    # avstd = np.nanstd(av, ddof = 1,  axis = 0)\n",
    "    # avstd[np.isnan(avstd)] = 0.2\n",
    "\n",
    "    avmed = sl.voxel_dAVdd\n",
    "    avstd = sl.voxel_dAVdd_std \n",
    "    # return 0\n",
    "    return np.sum( - 0.5 * (av - avmed[:, np.newaxis])**2 / (2 * avstd[:, np.newaxis]**2)) # first part might not be needed\n",
    "\n",
    "    # return np.sum(np.log(1/(avstd[:, np.newaxis] * np.sqrt(2 * np.pi ))) - 0.5 * (av - avmed[:, np.newaxis])**2 / (2 * avstd[:, np.newaxis]**2)) # first part might not be needed\n",
    "\n",
    "def logprob_2(p, sl = a, logprior = logprior_v, loglikely = loglikely_2, **kwargs):\n",
    "    ndim = len(sl.voxel_dAVdd)\n",
    "    v = p[ :ndim]\n",
    "    av = p[ndim:].reshape(-1, ndim)\n",
    "    # print(av.shape)\n",
    "\n",
    "    lp = logprior(v, **kwargs)\n",
    "    lp_davdd = logprior_davdd(av, AV_base = sl.dAVdd)\n",
    "    lp_davdd_reg = logprior_davdd_reg(av, sl, **kwargs)\n",
    "\n",
    "    if (not np.isfinite(lp)) | (not np.isfinite(lp_davdd)) | (not np.isfinite(lp_davdd_reg)):\n",
    "        # print('fail logprob')\n",
    "        return -np.inf\n",
    "    return lp + lp_davdd + lp_davdd_reg + loglikely_2(v, av, sl = sl, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MCMC(sl, steps = 1000, nwalkers = 100):\n",
    "    ndim = len(sl.voxel_dAVdd) \n",
    "    ndim_amp = int(2 * ndim)\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim_amp , logprob_2, \n",
    "                                    kwargs={'sl': sl, 'prior_mult':  3, 'v_max': 5, 'sigma': signal_errs})\n",
    "    init = 7.5 *(np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "  \n",
    "    init[:, ndim:] = np.abs(sl.voxel_dAVdd[np.newaxis, :] + 0.5*(np.random.random(init[:, ndim:].shape)-0.5))\n",
    "    print(init.shape)\n",
    "    sampler.run_mcmc(init,  steps);\n",
    "    \n",
    "    return sampler, ndim, ndim_amp\n",
    "\n",
    "\n",
    "def MCMC_scary(sl, steps = 1000, nwalkers = 100):\n",
    "    ndim = len(sl.voxel_dAVdd) \n",
    "    nstar = len(sl.stars)\n",
    "    ndim_amp = int(ndim + ndim * nstar)\n",
    "\n",
    "    # dAVdd_prior = sl.dAVdd[:]\n",
    "    # dAVdd_prior[dAVdd_prior == 0] = np.nan \n",
    "    # dAVdd_prior_med = np.nanmedian(dAVdd_prior, axis = 1)\n",
    "    # dAVdd_prior_std = np.nanstd(dAVdd_prior, axis = 1, ddof = 1)\n",
    "    # gaussparams = (dAVdd_prior_med, dAVdd_prior_std)\n",
    "    # print(gaussparams)\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim_amp , logprob_2, \n",
    "                                    kwargs={'sl': sl,  'prior_mult':  3, 'v_max': 5, 'sigma': signal_errs})\n",
    "    init = 7.5 *(np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "  \n",
    "    init[:, ndim:] = np.abs(sl.dAVdd.ravel()[np.newaxis, :] + 0.5*(np.random.random(init[:, ndim:].shape)-0.5))\n",
    "    # plt.hist(init[:, ndim:])\n",
    "    print(init.shape)\n",
    "\n",
    "    \n",
    "    sampler.run_mcmc(init,  steps);\n",
    "    \n",
    "    return sampler, ndim, ndim_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = 1500\n",
    "sampler, ndim, ndim_amp = MCMC_scary(a, steps = stp, nwalkers = 500)\n",
    "# sampler1, ndim1, ndim_amp1 = MCMC(a1, steps = stp)\n",
    "# sampler2, ndim2, ndim_amp2 = MCMC(a2, steps = stp)\n",
    "# sampler3, ndim3, ndim_amp3 = MCMC(a3, steps = stp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
