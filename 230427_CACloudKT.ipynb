{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import astropy.units as u  \n",
    "import astropy.constants as c\n",
    "from astropy.coordinates import SkyCoord, Galactic, CartesianRepresentation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, join\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "bayestar_path = '/uufs/astro.utah.edu/common/home/u1371365/dustmaps_data/bayestar/bayestar2019.h5'\n",
    "from dustmaps.bayestar import BayestarQuery\n",
    "\n",
    "### NEW 03-20: implement the 10pc resolution Vergely map into dustmaps ###\n",
    "from dustmaps.vergely2022 import Vergely2022Query\n",
    "\n",
    "import h5py\n",
    "from dustapprox.models import PrecomputedModel\n",
    "\n",
    "import emcee\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Query Bayestar dustmap ###\n",
    "# bayestar_path = '/uufs/astro.utah.edu/common/home/u1371365/dustmaps_data/bayestar/bayestar2019.h5'\n",
    "\n",
    "# bayestar = BayestarQuery(bayestar_path, version='bayestar2019')\n",
    "# bayestar_dist = (bayestar.distances.to(u.pc)).value\n",
    "# # distance = bayestar_dist[np.where(bayestar_dist < 1001)[0]]\n",
    "distance = np.linspace(0, 1000, 200)\n",
    "\n",
    "\n",
    "l0, b0 = (163., -8.0)\n",
    "l_ = np.linspace(l0 - 9., l0 + 9., 200)\n",
    "b_ = np.linspace(b0 - 9., b0 + 9., 200)\n",
    "l, b, d = np.meshgrid(l_, b_, distance)\n",
    "print(l.shape)\n",
    "\n",
    "coords = SkyCoord(l*u.deg, b*u.deg,\n",
    "                  distance=distance*u.pc, frame='galactic')\n",
    "\n",
    "# reddening = 2.742 * bayestar(coords, mode='percentile', pct = (50, 16, 84)).astype(float) #Av, from https://iopscience.iop.org/article/10.1088/0004-637X/737/2/103#apj398709t6\n",
    "# print(reddening.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Vergely+ (2022) dustmap for same points as Bayestar, now that it's in dustmaps\n",
    "A0Coeff = 1.052180128669157 # from 02-03dustmap_explore.ipynb, calculated via dustapprox\n",
    "\n",
    "vergelyquery = Vergely2022Query(map_fname = \n",
    "                                '/uufs/astro.utah.edu/common/home/u1371365/dustmaps_data/vergely2022/vergely22_extinction_density_resol_010pc.h5')\n",
    "vergely = vergelyquery(coords) * A0Coeff\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.imshow(np.sum(vergely * 5, axis = 2), origin = 'lower', cmap = 'binary', extent = (l0-9, l0+9, b0-9, b0+9))\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda0 = 15272.42 \n",
    "sigma0 = 1.15\n",
    "\n",
    "def get_wavs(hdulist = None, rv = 0):\n",
    "    if hdulist is None:\n",
    "        CRVAL1 = 4.179\n",
    "        CDELT1 = 6e-06\n",
    "        LEN = 8575\n",
    "    else:\n",
    "        header = hdulist[1].header\n",
    "        CRVAL1 = header['CRVAL1']\n",
    "        CDELT1 = header['CDELT1']\n",
    "        LEN = header['NAXIS1']\n",
    "        \n",
    "    wavs = np.power(10, CRVAL1 + CDELT1 * np.arange(LEN))\n",
    "    wavs = wavs * (1 + rv / 3e5) # allows for shifting to observed frame from rest frame\n",
    "    return wavs\n",
    "\n",
    "wavs = get_wavs()\n",
    "window = (wavs > lambda0 -10) & (wavs < lambda0 + 10)\n",
    "window_inds = np.where(window)[0]\n",
    "wavs_window = wavs[window]\n",
    "window_mask = (wavs_window < lambda0) - 5 | (wavs_window > lambda0 + 5)\n",
    "\n",
    "def dopplershift(v, lambda0 = lambda0):\n",
    "     return (lambda0 * u.Angstrom * (c.c + v * u.km / u.s) / c.c).to(u.Angstrom).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_meta = Table(fits.open('../Data/230420_CAResiduals/CA_meta.fits')[1].data)\n",
    "CAresdir = '../Data/230420_CAResiduals/'\n",
    "starhorsepath = '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'\n",
    "starhorse = Table.read(starhorsepath, hdu = 1)\n",
    "starhorse = starhorse['APOGEE_ID', 'dist16', 'dist50', 'dist84', 'AV16', 'AV50', 'AV84']\n",
    "\n",
    "CA_meta = join(CA_meta, starhorse, keys = 'APOGEE_ID', join_type = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_meta['DIST'][CA_meta['DIST'] < 0] = 0\n",
    "verg_stars = np.zeros((len(CA_meta), len(distance)))\n",
    "for i, star in enumerate(CA_meta):\n",
    "    dinds = distance < star['DIST']\n",
    "\n",
    "    verg_star = vergelyquery(SkyCoord(star['GLON'] * u.deg, star['GLAT']*u.deg, \n",
    "                                    distance=distance[dinds]*u.pc, frame = 'galactic'))\n",
    "    verg_stars[i, dinds ] = verg_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CA_meta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ca_res(fname):\n",
    "    return str(CAresdir + str(fname))\n",
    "\n",
    "for i in range(100):\n",
    "    asdf = get_ca_res(CA_meta[i]['FILE'])\n",
    "    try:\n",
    "        fits.open(asdf)\n",
    "    except:\n",
    "        print('file doesnt exist')\n",
    "\n",
    "def select_stars(tab, l0, b0, radius = 1):\n",
    "    cond = np.sqrt((tab['GLON'] - l0)**2 + (tab['GLAT'] - b0)**2) < radius\n",
    "    return np.where(cond)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loff = 1\n",
    "# boff = 1\n",
    "\n",
    "loff = 1\n",
    "boff = 1\n",
    "l_cen, b_cen, = (163 + loff , -8.4 + boff)\n",
    "s= select_stars(CA_meta, l_cen, b_cen, radius = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(CA_meta['DIST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(ll, bb):\n",
    "    l_sel = l_\n",
    "    b_sel = b_\n",
    "\n",
    "    return np.argmin(np.abs(l_sel - ll)), np.argmin(np.abs(b_sel - bb))\n",
    "\n",
    "def find_nearest_dist(d):\n",
    "    return np.argmin(np.abs(distance[:, np.newaxis] - d), axis = 0)\n",
    "\n",
    "\n",
    "def dAV_dd(l0, b0, bin_edges):\n",
    "    l_ind, b_ind = find_nearest(l0, b0)\n",
    "    sightline = np.copy(vergely[b_ind, l_ind, :])\n",
    "\n",
    "    d_min, d_max = bin_edges\n",
    "\n",
    "    extinction = sightline[(distance > d_min) & (distance < d_max)]\n",
    "    return np.sum(extinction )\n",
    "\n",
    "def dAV_dd_star(l0, b0, bin_edges, distances):\n",
    "    l_ind, b_ind = find_nearest(l0, b0)\n",
    "    d_min, d_max = bin_edges\n",
    "    sightline = np.copy(vergely[b_ind, l_ind, :])\n",
    "    sightline[(distance < d_min) | (distance > d_max)] = 0\n",
    "    sightline_av = (np.cumsum(sightline)) \n",
    "    d_ind = find_nearest_dist(distances)\n",
    "\n",
    "    return np.nanmedian(sightline_av[d_ind])\n",
    "\n",
    "# dAV_dd_star(l0, b0, (300, 480), CA_meta[sel1]['DIST'])\n",
    "\n",
    "\n",
    "def Differential_Amplitude(dAv_dd, dd):\n",
    "     return  0.024 * dAv_dd * dd  # 1/(np.sqrt(2 * np.pi) * sigma0) * 102e-3 * dAv_dd * dd\n",
    "\n",
    "    # dmin, dmax = bin_edges\n",
    "    # dustmap_values = vergely()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_DIBs(tab, return_unstacked = False):\n",
    "    dib_array = np.zeros((len(tab), len(wavs_window)))\n",
    "    dib_errs = np.zeros((len(tab), len(wavs_window)))\n",
    "    for i in range(len(tab)):\n",
    "        star = tab[i]\n",
    "\n",
    "        try:\n",
    "            res = fits.open(get_ca_res(star['FILE']))\n",
    "            dib_array[i, :] = res[1].data[window]\n",
    "            dib_errs[i, :] = res[2].data[window]\n",
    "        except:\n",
    "            dib_array[i, :] = np.nan\n",
    "            dib_errs[i, :] = np.nan\n",
    "\n",
    "    if return_unstacked:\n",
    "        return np.nanmedian(dib_array, axis = 0), dib_array\n",
    "    return np.nanmedian(dib_array, axis = 0), np.nanmedian(dib_errs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_bins(n, l_cen, b_cen, rad = 0.4, min_dist = 300, max_dist = 1000):\n",
    "    select = select_stars(CA_meta, l_cen, b_cen, radius = rad)\n",
    "\n",
    "    n_sightline = len(select)\n",
    "    distances = CA_meta['DIST'][select]\n",
    "    n_near = len(np.where(distances < min_dist))\n",
    "\n",
    "\n",
    "    if (n_sightline - n_near) < (n-1): \n",
    "        print('WARNING: NOT ENOUGH STARS IN SIGHTLINE')\n",
    "        n = n_sightline \n",
    "        print('NEW BIN NUMBER {}'.format(n))\n",
    "    if n_near == 0: \n",
    "        print('WARNING: SIGHTLINE CONTAINS NO STARS AT DIST < {} PC; '.format(min_dist))\n",
    "        min_dist = np.nanmin(distances)\n",
    "        print('NEW MIN DIST {} PC'.format(min_dist))\n",
    "\n",
    "    n_per_bin = (n_sightline - n_near) // (n-1)\n",
    "    n_extra = (n_sightline - n_near) % (n-1)\n",
    "\n",
    "    if max_dist is not None:\n",
    "        max_dist = np.nanmax(distances)\n",
    "    dist_range = max_dist - min_dist\n",
    "\n",
    "    dist_bin_avg = dist_range / (n-1)\n",
    "    \n",
    "    dist_bin_borders = np.arange(min_dist, max_dist + 1, dist_bin_avg)\n",
    "\n",
    "    iterate = True\n",
    "    iters = 0 \n",
    "\n",
    "    while iterate == True:\n",
    "        iters = iters + 1 \n",
    "        n_in_bin = np.array([len(np.where((distances > dist_bin_borders[i]) & (distances <= dist_bin_borders[i+1]))) \n",
    "                             for i in range(len(dist_bin_borders)-1)])\n",
    "\n",
    "        ##FIGURE THIS OUT\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get code to extract the necessary stellar residuals ###\n",
    "dist_bins = np.array([np.nanmin(CA_meta['DIST']), np.nanmean(CA_meta['DIST']), np.nanmax(CA_meta['DIST'])])\n",
    "# dist_bins = np.array([300, np.nanpercentile(CA_meta['DIST'], 33), np.nanpercentile(CA_meta['DIST'], 66)\n",
    "#                       , np.nanmax(CA_meta['DIST'])])\n",
    "dist_bins = np.array([300, np.nanpercentile(CA_meta['DIST'][s], 25), np.nanpercentile(CA_meta['DIST'][s], 50), np.nanpercentile(CA_meta['DIST'][s], 75)\n",
    "                      , np.nanmax(CA_meta['DIST'][s])])\n",
    "dist_bins[0] = 300\n",
    "print(dist_bins)\n",
    "\n",
    "voxel_dAv_dd = np.zeros(len(dist_bins))\n",
    "signals = np.zeros((len(dist_bins), len(window_inds)))\n",
    "signal_errs = np.zeros((len(dist_bins), len(window_inds)))\n",
    "\n",
    "\n",
    "for i in range(len(dist_bins) - 1):\n",
    "    bin_min, bin_max = (dist_bins[i], dist_bins[i+1])\n",
    "\n",
    "    sel = np.where((CA_meta['DIST'][s] > bin_min) & (CA_meta['DIST'][s] <= bin_max))[0]\n",
    "    # sel2 = np.where(CA_meta['DIST'][s] > dist_bins[1])[0]\n",
    "\n",
    "\n",
    "# loff = 1\n",
    "# boff = 5\n",
    "    # voxel_av1 = dAV_dd(l_cen, b_cen, (bin_min, bin_max))\n",
    "    voxel_av_ = dAV_dd_star(l_cen, b_cen, (bin_min, bin_max), CA_meta[s][sel]['DIST'])\n",
    "\n",
    "    # voxel_amp1 = Differential_Amplitude(voxel_av1, 5 )\n",
    "    voxel_amp_ = Differential_Amplitude(voxel_av_, 5 )\n",
    "\n",
    "    voxel_dAv_dd[i+1] = voxel_av_ \n",
    "\n",
    "    dstack, derrs = stack_DIBs(CA_meta[s][sel])\n",
    "    signals[i+1, :] = dstack\n",
    "    signal_errs[i+1, :] = derrs\n",
    "\n",
    "    \n",
    "\n",
    "    # voxel_av2 = dAV_dd(l_cen, b_cen, tuple(dist_bins[1:]))\n",
    "    # voxel_av2_ = dAV_dd_star(l_cen, b_cen, tuple(dist_bins[1:]), CA_meta[s][sel2]['DIST'])\n",
    "    # voxel_amp2 = Differential_Amplitude(voxel_av2, 5)\n",
    "    # voxel_amp2_ = Differential_Amplitude(voxel_av2_, 5)\n",
    "\n",
    "# print(voxel_av1 * 5, voxel_av2 * 5)\n",
    "# print(voxel_amp1, voxel_amp2)\n",
    "\n",
    "# print(voxel_av1_ * 5, voxel_av2_ * 5)\n",
    "# print(voxel_amp1_, voxel_amp2_)\n",
    "\n",
    "voxel_av0 = dAV_dd(l_cen, b_cen, (0, dist_bins[0])) # Av for pre-sample stars \n",
    "# voxel_amp0 = Differential_Amplitude(voxel_av0, 5)\n",
    "# print('Before Cloud: ', voxel_av0, voxel_amp0)\n",
    "voxel_dAv_dd[0] = voxel_av0\n",
    "\n",
    "sel0 = CA_meta['DIST'][s] < dist_bins[0]\n",
    "# print(sel0)\n",
    "signals[0, :], signal_errs[0, :] = stack_DIBs(CA_meta[s][sel0])\n",
    "print(signals)\n",
    "if np.any(np.isnan(signals)):\n",
    "    print('ABORT')\n",
    "\n",
    "# print(len(sel1), len(sel2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(CA_meta['DIST'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel_dAv_dd = np.array([voxel_av0, voxel_av1_, voxel_av2_])\n",
    "# voxel_dist = np.array([300, 486, 800])\n",
    "voxel_dist = dist_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(nrows = 1, ncols = 2, figsize = (12,6))\n",
    "# axs[0].imshow(np.sum(vergely * 5, axis = 2), origin = 'lower', cmap = 'binary', extent = (l0-9, l0+9, b0-9, b0+9))\n",
    "# axs[0].set_xlabel('l (deg)')\n",
    "# axs[0].set_ylabel('b (deg)')\n",
    "# axs[0].scatter(CA_meta['GLON'][s], CA_meta['GLAT'][s])\n",
    "\n",
    "# l_ind, b_ind = find_nearest(l_cen, b_cen)\n",
    "# axs[1].plot(distance, vergely[b_ind, l_ind, :] * 5)\n",
    "\n",
    "\n",
    "# norm_array = np.array([dist_bins[1]-dist_bins[0], dist_bins[1]-dist_bins[0], dist_bins[2] - dist_bins[1], dist_bins[2] - dist_bins[1]])\n",
    "# # axs[1].plot([dist_bins[0], dist_bins[1], dist_bins[1], dist_bins[2]], np.array([voxel_av1, voxel_av1, voxel_av2, voxel_av2]) / 5)\n",
    "# axs[1].plot([dist_bins[0], dist_bins[1], dist_bins[1], dist_bins[2]], np.array([voxel_av_, voxel_av1_, voxel_av2_, voxel_av2_]) / norm_array)\n",
    "\n",
    "# axs[1].scatter(CA_meta['DIST'][s], np.ones(len(CA_meta[s])) * 0.07)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# for i, star in enumerate(CA_meta[sel2]):\n",
    "#     ax.plot(distance, verg_stars[i, :], linestyle = 'dashed', alpha = .5, color = 'grey')\n",
    "# ax.plot(distance, vergely[b_ind, l_ind, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_ind, l_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_DIBs(tab, return_unstacked = False):\n",
    "    dib_array = np.zeros((len(tab), len(wavs_window)))\n",
    "    dib_errs = np.zeros((len(tab), len(wavs_window)))\n",
    "    for i in range(len(tab)):\n",
    "        star = tab[i]\n",
    "\n",
    "        try:\n",
    "            res = fits.open(get_ca_res(star['FILE']))\n",
    "            dib_array[i, :] = res[1].data[window]\n",
    "            dib_errs[i, :] = res[2].data[window]\n",
    "        except:\n",
    "            dib_array[i, :] = np.nan\n",
    "            dib_errs[i, :] = np.nan\n",
    "\n",
    "    if return_unstacked:\n",
    "        return np.nanmedian(dib_array, axis = 0), dib_array\n",
    "    return np.nanmedian(dib_array, axis = 0), np.nanmedian(dib_errs, axis = 0)\n",
    "\n",
    "# dstack0, derrs0 = stack_DIBs(CA_meta[CA_meta['DIST'] < 300])\n",
    "# dstack1, derrs1 = stack_DIBs(CA_meta[s][sel1])\n",
    "# dstack2, derrs2 = stack_DIBs(CA_meta[s][sel2])\n",
    "\n",
    "# # for i in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals = np.array([dstack0, dstack1, dstack2])\n",
    "# signal_errs = np.array([derrs0, derrs1, derrs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# for i in range(len(dstack)):\n",
    "#     ax.plot(wavs_window, dstack1[i, :], linewidth = 1, color = 'grey', alpha = 0.5)\n",
    "\n",
    "ax.plot(wavs_window, signals[1, :], label = '300-480 pc')\n",
    "ax.fill_between(wavs_window, signals[1, :] + signal_errs[1, :], signals[1, :] - signal_errs[1, :], color= 'C0', alpha = 0.1)\n",
    "\n",
    "ax.plot(wavs_window, signals[2, :], label = '480-800 pc')\n",
    "ax.fill_between(wavs_window, signals[2, :] + signal_errs[2, :], signals[2, :] - signal_errs[2, :], color= 'C1', alpha = 0.1)\n",
    "\n",
    "ax.plot(wavs_window, signals[0, :], label = '<300 pc', color = 'grey', linestyle = 'dashed')\n",
    "\n",
    "\n",
    "\n",
    "# ax.scatter(lambda0, 1 - (voxel_amp0 + voxel_amp1), label = '$\\sum$ voxel A(V)', c = 'C0',)\n",
    "# ax.scatter(lambda0, 1 - (voxel_amp0 + voxel_amp1 + voxel_amp2), c = 'C1',)\n",
    "\n",
    "\n",
    "# ax.scatter(lambda0, 1 - (voxel_amp0 + voxel_amp1_), c = 'C0', marker = '+', label = 'Med stellar A(V)')\n",
    "# ax.scatter(lambda0, 1 - (voxel_amp0 + voxel_amp1_ + voxel_amp2_), marker = '+', c = 'C1')\n",
    "# ax.scatter(lambda0, 1 - (voxel_amp0), c = 'k', marker = 'x', label = '< 300 pc')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "ax.set_ylabel('Normalized Flux')\n",
    "ax.legend(fontsize = 12)\n",
    "ax.set_ylim(0.94, 1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signals(rvelo, m = 0, b = 1, dAv_dd = voxel_dAv_dd, dist = voxel_dist, sigma0=sigma0, **kwargs):\n",
    "    signals = np.zeros((len(dist), len(wavs_window)))\n",
    "    amp = Differential_Amplitude(dAv_dd, dd = 5) # CONVERT THIS\n",
    "\n",
    "\n",
    "    peak_wavelength = dopplershift(rvelo)\n",
    "    wavs_grid = np.tile(wavs_window, (len(dist), 1))\n",
    "    voxel_DIB_unscaled = np.exp(-(wavs_grid - peak_wavelength[:, np.newaxis])**2 / (2 * sigma0**2))\n",
    "\n",
    "    def single_signal(dist_max, i, amp = amp):\n",
    "        # print(dist_max)\n",
    "        amp = -np.copy(amp)\n",
    "        amp[dist > dist_max] = 0\n",
    "        voxel_DIB_scaled = voxel_DIB_unscaled *  amp[:, np.newaxis] \n",
    "        summed_DIB = np.sum(voxel_DIB_scaled, axis = 0)\n",
    "        continuum = lambda x, m, b : m * (x - lambda0) + b\n",
    "        cont = continuum(wavs_window, m, b)\n",
    "\n",
    "        return summed_DIB  + cont\n",
    "    \n",
    "\n",
    "    for i in range(len(dist)):\n",
    "        dist_max = dist[i]\n",
    "        signals[i, :] = single_signal(dist_max, i)\n",
    "    \n",
    "    signals = signals #+ continuum(wavs_window, m, b)[np.newaxis, :]\n",
    "    return signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sig = make_signals(np.zeros(len(voxel_dist)))\n",
    "\n",
    "ax.plot(wavs_window, signals[1, :], label = '300-480 pc', c = 'C1')\n",
    "ax.plot(wavs_window, signals[2, :], label = '480-800 pc', color = 'C2')\n",
    "ax.plot(wavs_window, signals[0, :], label = '<300 pc', color = 'C0')\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    ax.plot(wavs_window, sig[i, :], c = 'C{}'.format(i), linestyle = 'dashed')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "ax.set_ylabel('Normalized flux' )\n",
    "\n",
    "# ax.text(15262, 1.01, 'continuum = $-(1e-4) (\\lambda - \\lambda0) + 1.005$' , fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log-likelihood etc. for first MCMC pass ###\n",
    "\n",
    "def loglikely_2(p, sigma = signal_errs, signal = signals, **kwargs):\n",
    "    v = p[:int(len(p)/2)]\n",
    "    av = p[int(len(p)/2):]\n",
    "    return - 0.5 * np.sum((signal - make_signals(v, dAv_dd = av, sigma0 = sigma0, **kwargs))**2 / (sigma**2)) \n",
    "\n",
    "def logprior_v(v, v_max = 5, prior_mult = 1, **kwargs):\n",
    "    if (np.any(np.abs(v) > prior_mult * v_max)):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def logprior_av(av, AV_base = voxel_dAv_dd, AV_max = 1):   \n",
    "    if (np.any(np.abs(av - AV_base) > AV_max)):\n",
    "        return -np.inf\n",
    "    if ((np.any(av < 0))):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def logprob_2(p, logprior = logprior_v, loglikely = loglikely_2, **kwargs):\n",
    "    # print('......')\n",
    "    # print(p.shape)\n",
    "    # print(p)\n",
    "    # print('......')\n",
    "    v = p[ :int(len(p)/2)]\n",
    "    av = p[int(len(p)/2):]\n",
    "    # sig = p[-1]\n",
    "    lp = logprior(v, **kwargs)\n",
    "    lp_av = logprior_av(av)\n",
    "\n",
    "    if (not np.isfinite(lp)) | (not np.isfinite(lp_av)):\n",
    "        return -np.inf\n",
    "    return lp + lp_av + loglikely(p, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikely(p, sigma = signal_errs, signal = signals, **kwargs):\n",
    "    v = p\n",
    "    # m = p[:, 3] / 10\n",
    "    # m = 0\n",
    "    # b = p[:, 3] / 10\n",
    "    # print(b)\n",
    "    # b = 1\n",
    "    return - 0.5 * np.sum((signal - make_signals(v, **kwargs))**2 / (sigma**2)) \n",
    "\n",
    "def logprior(v, v_max = 5, prior_mult = 1, **kwargs):\n",
    "    if (np.any(np.abs(v) > prior_mult * v_max)):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "\n",
    "def logprob(v, logprior = logprior, loglikely = loglikely, **kwargs):\n",
    "    lp = logprior(v, **kwargs)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + loglikely(v, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = len(voxel_dist) \n",
    "ndim_amp = int(2 * ndim)\n",
    "def MCMC1(dAV_dd, steps = 1000, nwalkers = 100):\n",
    "\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim_amp , logprob_2, \n",
    "                                    kwargs={'prior_mult':  3, 'v_max': 5, 'sigma': signal_errs})\n",
    "    init = 5 *(np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "    init[:, ndim:] = np.abs(dAV_dd[np.newaxis, :] + 0.5*(np.random.random(init[:, ndim:].shape)-0.5))\n",
    "    \n",
    "    sampler.run_mcmc(init,  steps);\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "def MCMC2(dAV_dd, init, steps = 1000, nwalkers = 100):\n",
    "    ndim = len(voxel_dist) \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim , logprob, \n",
    "                                    kwargs  = {'prior_mult':  3, 'v_max': 10, 'sigma': signal_errs})\n",
    "\n",
    "    sampler.run_mcmc(init, steps)\n",
    "\n",
    "    return sampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_signals(vel, dAv_dd = voxel_dAv_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = samp1.chain[:, :, :].reshape((-1, ndim_amp))\n",
    "# np.nanmedian(samples, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp1 = MCMC1(voxel_dAv_dd, steps=500)\n",
    "\n",
    "init = samp1.chain[:,-1, :ndim]\n",
    "samples = samp1.chain[:, :, :].reshape((-1, ndim_amp))\n",
    "med_dAV_dd = np.nanmedian(samples[50:, ndim:], axis = 0)\n",
    "\n",
    "samp2 = MCMC2(med_dAV_dd, init, steps = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burnin(sampler, i, label = ''):\n",
    "    fig, ax = plt.subplots(figsize = (20, 6))\n",
    "\n",
    "    normalize = matplotlib.colors.Normalize(-10, 10)\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmappable = matplotlib.cm.ScalarMappable(norm = normalize, cmap = cmap)\n",
    "    colors = cmap(np.linspace(0,1,ndim))\n",
    "\n",
    "    # for i in range(ndim):\n",
    "    walkers = sampler.chain[:,:,i].T\n",
    "    points = ax.plot(walkers)\n",
    "\n",
    "    cutoff = 100\n",
    "    median = np.median(walkers[100:, :])\n",
    "    perc16err =  median - np.percentile(walkers[100:, :], 16) \n",
    "    perc84err =  np.percentile(walkers[100:, :], 84) - median\n",
    "    stdeviation =  np.std(walkers[100,:], ddof = 1)\n",
    "\n",
    "\n",
    "    plt.errorbar(x = 500 + 0.05 * 500, y = median, yerr = stdeviation, fmt = 'o', capsize = 2)\n",
    "\n",
    "    # fig.colorbar(cmappable, label = 'Velocity ')\n",
    "    ax.set_xlabel(\"Walker Steps\")\n",
    "    ax.set_ylabel(label)\n",
    "    plt.show()\n",
    "\n",
    "burnin(samp1, -1, label = 'dAV_dd')\n",
    "burnin(samp2, 1, label = 'Velo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corner(sampler, labels):\n",
    "    dim = sampler.chain.shape[-1]\n",
    "    samples = sampler.chain[:, 50:, :].reshape((-1, dim))\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    plt.show()\n",
    "\n",
    "labels = ['RVELO1', 'RVELO2', 'RVELO3', 'RVELO4', 'RVELO5', 'RVELO6', 'RVELO7']\n",
    "# make_corner(samp1, labels = labels)\n",
    "make_corner(samp2, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_DIBS(sampler):\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    # ax.plot(wavs_window, dstack1, label = '300-480 pc')\n",
    "    # ax.plot(wavs_window, dstack2, label = '480-800 pc')\n",
    "\n",
    "    samples = sampler.chain[:, 50:, :].reshape((-1, sampler.chain.shape[-1]))\n",
    "\n",
    "    median_0 = np.nanmedian(samples[50:, 0])\n",
    "    median_1 = np.nanmedian(samples[50:, 1])\n",
    "    median_2 = np.nanmedian(samples[50:, 2])\n",
    "    # median_3 = np.nanmedian(samples[50:, 3])\n",
    "    # median_4 = np.nanmedian(samples[50:, 4])\n",
    "    # median_5 = np.nanmedian(samples[50:, 5])\n",
    "    # median_6 = np.nanmedian(samples[50:, 6])\n",
    "    print(samples.shape)\n",
    "    medians = np.nanmedian(samples[50:, :], axis = 0)\n",
    "\n",
    "    print(medians)\n",
    "    print(medians.shape)\n",
    "\n",
    "\n",
    "    std_1 = np.std(samples[50:, 1], ddof = 1)\n",
    "    std_2 = np.std(samples[50:, 2], ddof = 1)\n",
    "\n",
    "    signal_recreated = make_signals(medians, dAv_dd = med_dAV_dd, sigma0 = sigma0)\n",
    "    for i in range(len(signal_recreated)):\n",
    "        ax.plot(wavs_window, signals[i, :], color = 'C{}'.format(i))\n",
    "        ax.plot(wavs_window, signal_recreated[i, :], color = 'C{}'.format(i), linestyle = 'dashed',)# label = 'recreated signal')\n",
    "        # ax.plot(wavs_window, signal_recreated[2, :], color = 'C1', linestyle = 'dashed')\n",
    "\n",
    "    ax.legend(loc = 'lower left')\n",
    "\n",
    "    ax.set_xlabel('Wavelength $\\AA$')\n",
    "    ax.set_ylabel('Normalized Flux')\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    ax.set_xticks(np.arange(lambda0-10, lambda0 + 12, 4))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_DIBS(samp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samp2.chain[:, 50:, :].reshape((-1, samp2.chain.shape[-1]))\n",
    "velo_median = np.nanmedian(samples[50:, :], axis = 0)\n",
    "velo_stdev = np.nanstd(samples[50:, :], axis = 0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(voxel_dist, velo_median, zorder = 3)\n",
    "ax.errorbar(voxel_dist, velo_median, yerr = velo_stdev, fmt = '.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (20, 6))\n",
    "\n",
    "# normalize = matplotlib.colors.Normalize(-10, 10)\n",
    "# cmap = matplotlib.cm.viridis\n",
    "# cmappable = matplotlib.cm.ScalarMappable(norm = normalize, cmap = cmap)\n",
    "# colors = cmap(np.linspace(0,1,ndim))\n",
    "\n",
    "# # for i in range(ndim):\n",
    "# i = -1\n",
    "# walkers = samp2.chain[:,:,i].T\n",
    "# print(walkers.shape)\n",
    "# points = ax.plot(walkers)\n",
    "\n",
    "# cutoff = 100\n",
    "# median = np.median(walkers[100:, :])\n",
    "# perc16err =  median - np.percentile(walkers[100:, :], 16) \n",
    "# perc84err =  np.percentile(walkers[100:, :], 84) - median\n",
    "# stdeviation =  np.std(walkers[100,:], ddof = 1)\n",
    "# print(perc16err)\n",
    "# print(median)\n",
    "# print(perc84err)\n",
    "\n",
    "\n",
    "# plt.errorbar(x = steps + 0.05 * steps, y = median, yerr = stdeviation, fmt = 'o', capsize = 2)\n",
    "\n",
    "# # fig.colorbar(cmappable, label = 'Velocity ')\n",
    "# ax.set_xlabel(\"Walker Steps\")\n",
    "# # ax.set_ylabel('Radial Velocity (km/s)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = sampler.chain[:, 50:, :].reshape((-1, ndim_amp))\n",
    "\n",
    "# # median_3 = np.nanmedian(samples[50:, 3])\n",
    "# # median_4 = np.nanmedian(samples[50:, 4])\n",
    "# # median_5 = np.nanmedian(samples[50:, 5])\n",
    "# samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.chain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nwalkers = 100 # + 50 + 50 + 50\n",
    "# ndim = len(voxel_dist)\n",
    "# ndim = len(voxel_dist) \n",
    "# ndim_amp = int(2 * ndim)\n",
    "# prior_mult = 2\n",
    "\n",
    "# sampler = emcee.EnsembleSampler(nwalkers, ndim_amp , logprob_2, kwargs  = {'prior_mult':  4, 'v_max': 5, 'sigma': signal_errs})\n",
    "\n",
    "# init = 5 *(np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "# init[:, ndim:] = np.abs(voxel_dAv_dd[np.newaxis, :] + 0.5*(np.random.random(init[:, 3:].shape)-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel_dAv_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (20, 6))\n",
    "\n",
    "# normalize = matplotlib.colors.Normalize(-10, 10)\n",
    "# cmap = matplotlib.cm.viridis\n",
    "# cmappable = matplotlib.cm.ScalarMappable(norm = normalize, cmap = cmap)\n",
    "# colors = cmap(np.linspace(0,1,ndim))\n",
    "\n",
    "# # for i in range(ndim):\n",
    "# i = -1\n",
    "# walkers = sampler.chain[:,:,i].T\n",
    "# print(walkers.shape)\n",
    "# points = ax.plot(walkers)\n",
    "\n",
    "# cutoff = 100\n",
    "# median = np.median(walkers[100:, :])\n",
    "# perc16err =  median - np.percentile(walkers[100:, :], 16) \n",
    "# perc84err =  np.percentile(walkers[100:, :], 84) - median\n",
    "# stdeviation =  np.std(walkers[100,:], ddof = 1)\n",
    "# print(perc16err)\n",
    "# print(median)\n",
    "# print(perc84err)\n",
    "\n",
    "\n",
    "# plt.errorbar(x = steps + 0.05 * steps, y = median, yerr = stdeviation, fmt = 'o', capsize = 2)\n",
    "\n",
    "# # fig.colorbar(cmappable, label = 'Velocity ')\n",
    "# ax.set_xlabel(\"Walker Steps\")\n",
    "# # ax.set_ylabel('Radial Velocity (km/s)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['{} pc'.format(i) for i in ['<300', '300-480', '>480']]\n",
    "# print(labels)\n",
    "# samples = sampler.chain[:, 50:, :].reshape((-1, ndim_amp))\n",
    "\n",
    "# median_3 = np.nanmedian(samples[50:, 3])\n",
    "# median_4 = np.nanmedian(samples[50:, 4])\n",
    "# median_5 = np.nanmedian(samples[50:, 5])\n",
    "# dAV_dd_mc = np.array([median_3, median_4, median_5])\n",
    "\n",
    "\n",
    "# fig = corner.corner(samples, figsize = (20, 20))\n",
    "# for ax in fig.axes:\n",
    "    # ax.set_xlim(-10, 10)\n",
    "    # ax.set_ylim(-20, 20) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = sampler.chain\n",
    "# init = chain[:, -1, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndim = len(voxel_dist) \n",
    "\n",
    "# sampler = emcee.EnsembleSampler(nwalkers, ndim , logprob, kwargs  = {'prior_mult':  prior_mult, 'v_max': 10, 'sigma': signal_errs})\n",
    "# # init =  np.tile(voxel_rvelo, nwalkers).reshape((nwalkers, ndim)) + np.random.normal(0, 1/np.sqrt(SNR), (nwalkers, ndim))\n",
    "# # init = 5 *(np.random.random((nwalkers, ndim)) - 0.5)\n",
    "# init[:, -1] = 2 + np.random.random(nwalkers) \n",
    "# init = np.hstack([init, 10 * np.ones(nwalkers).T[:, np.newaxis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['{} pc'.format(i) for i in ['<300', '300-480', '>480']]\n",
    "# print(labels)\n",
    "# samples = sampler.chain[:, 50:, :].reshape((-1, 3))\n",
    "# fig = corner.corner(samples, figsize = (20, 20), labels = ['1', '2', '3'])\n",
    "# # for ax in fig.axes:\n",
    "#     # ax.set_xlim(-10, 10)\n",
    "#     # ax.set_ylim(-20, 20) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (20, 6))\n",
    "\n",
    "# normalize = matplotlib.colors.Normalize(-10, 10)\n",
    "# cmap = matplotlib.cm.viridis\n",
    "# cmappable = matplotlib.cm.ScalarMappable(norm = normalize, cmap = cmap)\n",
    "# colors = cmap(np.linspace(0,1,ndim))\n",
    "\n",
    "# # for i in range(ndim):\n",
    "# i = 1\n",
    "# walkers = sampler.chain[:,:,i].T\n",
    "# print(walkers.shape)\n",
    "# points = ax.plot(walkers)\n",
    "\n",
    "# cutoff = 100\n",
    "# median = np.median(walkers[100:, :])\n",
    "# perc16err =  median - np.percentile(walkers[100:, :], 16) \n",
    "# perc84err =  np.percentile(walkers[100:, :], 84) - median\n",
    "# stdeviation =  np.std(walkers[100,:], ddof = 1)\n",
    "# print(perc16err)\n",
    "# print(median)\n",
    "# print(perc84err)\n",
    "\n",
    "\n",
    "# plt.errorbar(x = steps + 0.05 * steps, y = median, yerr = stdeviation, fmt = 'o', capsize = 2)\n",
    "\n",
    "# # fig.colorbar(cmappable, label = 'Velocity ')\n",
    "# ax.set_xlabel(\"Walker Steps\")\n",
    "# ax.set_ylabel('Radial Velocity (km/s)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_dAv_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dAV_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = samp2.chain[:, 50:, :].reshape((-1, samp2.chain.shape[-1]))\n",
    "# vel = np.nanmedian(samples, axis = 0)\n",
    "# make_signals(vel, dAv_dd = med_dAV_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize = (8,6))\n",
    "# ax.plot(wavs_window, dstack1, label = '300-480 pc')\n",
    "# ax.plot(wavs_window, dstack2, label = '480-800 pc')\n",
    "\n",
    "# median_0 = np.nanmedian(samples[50:, 0])\n",
    "# median_1 = np.nanmedian(samples[50:, 1])\n",
    "# median_2 = np.nanmedian(samples[50:, 2])\n",
    "# # median_3 = np.nanmedian(samples[50:, 3])\n",
    "# # median_4 = np.nanmedian(samples[50:, 4])\n",
    "# # median_5 = np.nanmedian(samples[50:, 5])\n",
    "# # median_6 = np.nanmedian(samples[50:, 6])\n",
    "\n",
    "\n",
    "# std_1 = np.std(samples[50:, 1], ddof = 1)\n",
    "# std_2 = np.std(samples[50:, 2], ddof = 1)\n",
    "\n",
    "# signal_recreated = make_signals(np.array([median_0, median_1, median_2]),dAv_dd = dAV_dd_mc, sigma0 = sigma0)\n",
    "# ax.plot(wavs_window, signal_recreated[1, :], color = 'C0', linestyle = 'dashed', label = 'recreated signal')\n",
    "# ax.plot(wavs_window, signal_recreated[2, :], color = 'C1', linestyle = 'dashed')\n",
    "\n",
    "# ax.legend(loc = 'lower left')\n",
    "\n",
    "# ax.set_xlabel('Wavelength $\\AA$')\n",
    "# ax.set_ylabel('Normalized Flux')\n",
    "# fig.set_facecolor('white')\n",
    "\n",
    "# ax.set_xticks(np.arange(lambda0-10, lambda0 + 12, 4))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIB-AV relationship of stars in individual bins, and of the bins themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter([0,1],[median_1, median_2])\n",
    "# ax.errorbar([0,1], [median_1, median_2], yerr = [std_1, std_2], fmt = '.')\n",
    "# ax.set_xticks([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
